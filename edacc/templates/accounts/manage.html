{% extends "base.html" %}
{% block title %}Manage{% endblock %}
{% block content %}
    <div style="width:900px;">
        <p>
            Dear SAT Challenge 2012 Registrants,<br/>
        <p>
            We have noticed that there is some misunderstanding on what the currently
            open solver testing phase is meant for. Please read this email carefully.
            Misuse of the testing phase may in the worst case result in closing your
            account to the system and you being banned from participation in SAT
            Challenge 2012.
        </p>
        <p>
            The testing service is provided *only* to allow the competitors to check
            that their solvers *behave as expected* on the computing cluster.
        </p>
        <p>
            The testing interface is NOT MEANT FOR:<br/>
            -Repeated test-runs using different versions of your solvers.<br/>
            -Fine-tuning your solvers.
        </p>
        <p>
            Notice also that the instances used in the testing phase will not be used
            as benchmarks in the actual competition. Hence, it does not make sense to
            repeatedly submit solvers in attempt to solve all the testing instances.
        </p>
        <p>
            Any test-runs related to solver development should be conducted on your own
            computing resources, not via the testing interface. You should submit your
            solver for testing only after you are otherwise happy with the performance
            of your solver.
        </p>
        <p>
            The cluster computations are not cheap, and our resources are limited.
        </p>
        <p>
            In case we notice that a registrant repeatedly misuses the testing
            interface, we may be forced to close the account of the registrant.
        </p>
        <p>
            In case you have any questions, do not hesitate to contact us.<br/>
        </p>
        <p>
            Best regards,<br/>
            SAT Challenge 2012 Organizers
        </p>
        </p>
    </div>
<h2>Solver and benchmark submission</h2>
<div>
    Note that you can submit multiple solvers while testing the compatibility with our execution environment.<br/>
    Before the submission deadline please remove all solvers but the ones you wish to enter into the competition.<br/>
</div>
<ul>
    <li>
        <a href="{{url_for('accounts.submit_solver', database=database)}}">Submit a solver</a>
    </li>
    <li>
        <a href="{{url_for('accounts.list_solvers', database=database, user_id=g.User.idUser)}}">List of submitted solvers</a>
    </li>

    <li>
        <a href="{{url_for('accounts.submit_benchmarks', database=database)}}">Submit benchmarks</a>
    </li>
    <li>
        <a href="{{url_for('accounts.list_benchmarks', database=database)}}">List of submitted benchmarks</a>
    </li>

</ul>

<h2>Troubleshooting</h2>
<div style="width: 600px;">
    <ul>
        <li>Immediate solver crashes (close to 0 walltime) with the result "SIGSEGV" often indicate that the binary is not compatible with the kernel ("FATAL: Kernel too old").</li>
        <li>If your solver runs crash or only produce "unknown" results please first make sure that the parameters of your solver were parsed and used correctly. See Results->Experiment->List of solver configurations used->Select your solver.</li>
        <li>Check the individual runs by clicking on the ID in the "Live information about experiment progress" table or on a run in any of the result pages. The exact launch command appears in the "Launcher output" section.</li>
        <li>The "run command" in the solver submission form should only be used for interpreters/VMs like java or python, i.e. programs that are available system-wide.</li>
        <li>Don't hesitate to contact us if there are problems.</li>
    </ul>
</div>

{% endblock %}
